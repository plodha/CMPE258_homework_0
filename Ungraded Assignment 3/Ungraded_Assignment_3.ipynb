{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ungraded_Assignment_3.ipynb","provenance":[],"authorship_tag":"ABX9TyPgiI0eUTvsJjOEPr8Pgv3/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hs2PzeW-7noA","colab_type":"text"},"source":["#Ungraded Assignment 3"]},{"cell_type":"markdown","metadata":{"id":"X-SnOKw47r0S","colab_type":"text"},"source":["Finish Exercise 1,2,3,4 from Coursera"]},{"cell_type":"markdown","metadata":{"id":"DqRcHVCC74vd","colab_type":"text"},"source":["## Exercise 1"]},{"cell_type":"code","metadata":{"id":"eI-b-cBw7ilx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7cf0def2-f21f-4d6f-f662-7855f83b0579","executionInfo":{"status":"ok","timestamp":1589774632521,"user_tz":420,"elapsed":426,"user":{"displayName":"Pranav Lodha","photoUrl":"","userId":"17488211667113804286"}}},"source":["import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","np.random.seed(1)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EOQdUkim8Son","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: zero_pad\n","\n","def zero_pad(X, pad):\n","    \"\"\"\n","    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n","    as illustrated in Figure 1.\n","    \n","    Argument:\n","    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n","    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n","    \n","    Returns:\n","    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n","    \"\"\"\n","    \n","    ### START CODE HERE ### (≈ 1 line)\n","    X_pad = np.pad(X, ((0,0),(pad, pad), (pad, pad), (0,0)), 'constant', constant_values=(0,0))\n","    ### END CODE HERE ###\n","    \n","    return X_pad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6eFE9g98Y9Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":412},"outputId":"3925eb5f-e25d-4a9a-cc76-7ed9e4affaaa","executionInfo":{"status":"ok","timestamp":1589774632985,"user_tz":420,"elapsed":878,"user":{"displayName":"Pranav Lodha","photoUrl":"","userId":"17488211667113804286"}}},"source":["np.random.seed(1)\n","x = np.random.randn(4, 3, 3, 2)\n","x_pad = zero_pad(x, 2)\n","print (\"x.shape =\", x.shape)\n","print (\"x_pad.shape =\", x_pad.shape)\n","print (\"x[1,1] =\", x[1,1])\n","print (\"x_pad[1,1] =\", x_pad[1,1])\n","\n","fig, axarr = plt.subplots(1, 2)\n","axarr[0].set_title('x')\n","axarr[0].imshow(x[0,:,:,0])\n","axarr[1].set_title('x_pad')\n","axarr[1].imshow(x_pad[0,:,:,0])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["x.shape = (4, 3, 3, 2)\n","x_pad.shape = (4, 7, 7, 2)\n","x[1,1] = [[ 0.90085595 -0.68372786]\n"," [-0.12289023 -0.93576943]\n"," [-0.26788808  0.53035547]]\n","x_pad[1,1] = [[0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fceb5b90eb8>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"S-dyQQ-k85dG","colab_type":"text"},"source":["## Exercise 2"]},{"cell_type":"code","metadata":{"id":"cIdKyefS8c1U","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: conv_single_step\n","\n","def conv_single_step(a_slice_prev, W, b):\n","    \"\"\"\n","    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n","    of the previous layer.\n","    \n","    Arguments:\n","    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n","    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n","    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n","    \n","    Returns:\n","    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n","    \"\"\"\n","\n","    ### START CODE HERE ### (≈ 2 lines of code)\n","    # Element-wise product between a_slice and W. Do not add the bias yet.\n","    s = a_slice_prev * W\n","    # Sum over all entries of the volume s.\n","    Z = np.sum(s)\n","    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n","    Z = float(Z + b)\n","    ### END CODE HERE ###\n","\n","    return Z"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XBBxxDT8hPO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b3ab5e55-1463-417d-fd7d-4828bc44d9dc","executionInfo":{"status":"ok","timestamp":1589774632987,"user_tz":420,"elapsed":871,"user":{"displayName":"Pranav Lodha","photoUrl":"","userId":"17488211667113804286"}}},"source":["np.random.seed(1)\n","a_slice_prev = np.random.randn(4, 4, 3)\n","W = np.random.randn(4, 4, 3)\n","b = np.random.randn(1, 1, 1)\n","\n","Z = conv_single_step(a_slice_prev, W, b)\n","print(\"Z =\", Z)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Z = -6.999089450680221\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IGv5QdhW83Li","colab_type":"text"},"source":["## Exercise 3"]},{"cell_type":"code","metadata":{"id":"dL6R3E-N8jrs","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: conv_forward\n","\n","def conv_forward(A_prev, W, b, hparameters):\n","    \"\"\"\n","    Implements the forward propagation for a convolution function\n","    \n","    Arguments:\n","    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n","    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n","    hparameters -- python dictionary containing \"stride\" and \"pad\"\n","        \n","    Returns:\n","    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n","    cache -- cache of values needed for the conv_backward() function\n","    \"\"\"\n","    \n","    ### START CODE HERE ###\n","    # Retrieve dimensions from A_prev's shape (≈1 line)  \n","    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n","    \n","    # Retrieve dimensions from W's shape (≈1 line)\n","    (f, f, n_C_prev, n_C) = np.shape(W)\n","    \n","    # Retrieve information from \"hparameters\" (≈2 lines)\n","    stride = hparameters['stride']\n","    pad = hparameters['pad']\n","    \n","    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n","    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n","    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n","    \n","    # Initialize the output volume Z with zeros. (≈1 line)\n","    Z = np.zeros((m, n_H, n_W, n_C))\n","    \n","    # Create A_prev_pad by padding A_prev\n","    A_prev_pad = zero_pad(A_prev, pad)\n","    \n","    for i in range(m):                               # loop over the batch of training examples\n","        a_prev_pad = A_prev_pad[i,:,:,:]                               # Select ith training example's padded activation\n","        for h in range(n_H):                           # loop over vertical axis of the output volume\n","            for w in range(n_W):                       # loop over horizontal axis of the output volume\n","                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n","                    \n","                    # Find the corners of the current \"slice\" (≈4 lines)\n","                    vert_start = h * stride\n","                    vert_end = h * stride+ f\n","                    horiz_start = w * stride\n","                    horiz_end = w * stride + f\n","                    \n","                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n","                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n","                    \n","                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n","                    Z[i, h, w, c] = conv_single_step(a_slice_prev,W[:,:,:,c], b[:,:,:,c])\n","                                        \n","    ### END CODE HERE ###\n","    \n","    # Making sure your output shape is correct\n","    assert(Z.shape == (m, n_H, n_W, n_C))\n","    \n","    # Save information in \"cache\" for the backprop\n","    cache = (A_prev, W, b, hparameters)\n","    \n","    return Z, cache"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlKbXMAE8njo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"ee7b9fce-3ebe-477e-b70c-21bd82da5c2f","executionInfo":{"status":"ok","timestamp":1589774633141,"user_tz":420,"elapsed":1019,"user":{"displayName":"Pranav Lodha","photoUrl":"","userId":"17488211667113804286"}}},"source":["np.random.seed(1)\n","A_prev = np.random.randn(10,4,4,3)\n","W = np.random.randn(2,2,3,8)\n","b = np.random.randn(1,1,1,8)\n","hparameters = {\"pad\" : 2,\n","               \"stride\": 2}\n","\n","Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n","print(\"Z's mean =\", np.mean(Z))\n","print(\"Z[3,2,1] =\", Z[3,2,1])\n","print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Z's mean = 0.048995203528855794\n","Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n","  5.18531798  8.75898442]\n","cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OdMFRICS81OQ","colab_type":"text"},"source":["## Exercise 4"]},{"cell_type":"code","metadata":{"id":"Osr8aMY48pwf","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: pool_forward\n","\n","def pool_forward(A_prev, hparameters, mode = \"max\"):\n","    \"\"\"\n","    Implements the forward pass of the pooling layer\n","    \n","    Arguments:\n","    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    hparameters -- python dictionary containing \"f\" and \"stride\"\n","    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n","    \n","    Returns:\n","    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n","    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n","    \"\"\"\n","    \n","    # Retrieve dimensions from the input shape\n","    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n","    \n","    # Retrieve hyperparameters from \"hparameters\"\n","    f = hparameters[\"f\"]\n","    stride = hparameters[\"stride\"]\n","    \n","    # Define the dimensions of the output\n","    n_H = int(1 + (n_H_prev - f) / stride)\n","    n_W = int(1 + (n_W_prev - f) / stride)\n","    n_C = n_C_prev\n","    \n","    # Initialize output matrix A\n","    A = np.zeros((m, n_H, n_W, n_C))              \n","    \n","    ### START CODE HERE ###\n","    for i in range(m):                         # loop over the training examples\n","        for h in range(n_H):                     # loop on the vertical axis of the output volume\n","            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n","                for c in range (n_C):            # loop over the channels of the output volume\n","                    \n","                    # Find the corners of the current \"slice\" (≈4 lines)\n","                    vert_start = h * stride\n","                    vert_end = h * stride+ f\n","                    horiz_start = w * stride\n","                    horiz_end = w * stride + f\n","                    \n","                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n","                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end,c]\n","                    \n","                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n","                    if mode == \"max\":\n","                        A[i, h, w, c] = np.max(a_prev_slice)\n","                    elif mode == \"average\":\n","                        A[i, h, w, c] = np.mean(a_prev_slice)\n","    \n","    ### END CODE HERE ###\n","    \n","    # Store the input and hparameters in \"cache\" for pool_backward()\n","    cache = (A_prev, hparameters)\n","    \n","    # Making sure your output shape is correct\n","    assert(A.shape == (m, n_H, n_W, n_C))\n","    \n","    return A, cache"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7QCEB0I8ukx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"f933c4f3-9702-4d6c-9a99-b38b9709bb41","executionInfo":{"status":"ok","timestamp":1589774633142,"user_tz":420,"elapsed":1014,"user":{"displayName":"Pranav Lodha","photoUrl":"","userId":"17488211667113804286"}}},"source":["np.random.seed(1)\n","A_prev = np.random.randn(2, 4, 4, 3)\n","hparameters = {\"stride\" : 2, \"f\": 3}\n","\n","A, cache = pool_forward(A_prev, hparameters)\n","print(\"mode = max\")\n","print(\"A =\", A)\n","print()\n","A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n","print(\"mode = average\")\n","print(\"A =\", A)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["mode = max\n","A = [[[[1.74481176 0.86540763 1.13376944]]]\n","\n","\n"," [[[1.13162939 1.51981682 2.18557541]]]]\n","\n","mode = average\n","A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n","\n","\n"," [[[-0.22154621  0.51716526  0.48155844]]]]\n"],"name":"stdout"}]}]}